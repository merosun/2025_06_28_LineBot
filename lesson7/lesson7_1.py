import os
import streamlit as st
from google import genai
from google.genai import types
import inspect; print(inspect.signature(types.Part.from_text))

st.set_page_config(page_title="Gemini Chat", page_icon="ğŸ’¬")
API_KEY = os.environ.get("GEMINI_API_KEY")
MODEL = "gemini-2.5-flash"

if not API_KEY:
    st.error("è«‹å…ˆè¨­å®š GEMINI_API_KEY ç’°å¢ƒè®Šæ•¸")
    st.stop()

client = genai.Client(api_key=API_KEY)

if "history" not in st.session_state:
    st.session_state.history = []

st.title("ğŸ’¬ Gemini Chatï¼ˆç¹é«”ä¸­æ–‡ï¼‰")

for m in st.session_state.history:
    with st.chat_message("user" if m["role"] == "user" else "assistant"):
        st.markdown(m["text"])

uploaded_files = st.file_uploader(
    "ï¼ˆé¸å¡«ï¼‰ä¸Šå‚³åœ–ç‰‡ï¼šæ”¯æ´ jpg/png/webp",
    type=["jpg", "jpeg", "png", "webp"],
    accept_multiple_files=True
)

if uploaded_files:
    cols = st.columns(min(3, len(uploaded_files)))
    for i, f in enumerate(uploaded_files):
        with cols[i % len(cols)]:
            st.image(f, caption=f.name, use_container_width=True)

user_input = st.chat_input("è¼¸å…¥ä½ çš„å•é¡Œâ€¦ï¼ˆå¯å…ˆé¸åœ–ç‰‡å†æå•ï¼‰")

if user_input or uploaded_files:
    display_text = user_input if user_input else "(ç„¡æ–‡å­—)"
    if uploaded_files:
        display_text += f"\nï¼ˆé™„ {len(uploaded_files)} å¼µåœ–ç‰‡ï¼‰"
    st.session_state.history.append({"role": "user", "text": display_text})

    with st.chat_message("user"):
        st.markdown(display_text)

    def build_prompt(history):
        lines = ["ä½ æ˜¯ä¸€å€‹è‚¡å¸‚è²¡ç¶“å°ˆå®¶ï¼Œè«‹ç”¨ç¹é«”ä¸­æ–‡å›ç­”ã€‚ä»¥ä¸‹æ˜¯éå»å°è©±ï¼š"]
        for m in history:
            prefix = "ä½¿ç”¨è€…" if m["role"] == "user" else "åŠ©ç†"
            lines.append(f"{prefix}ï¼š{m['text']}")
        return "\n".join(lines)

    with st.chat_message("assistant"):
        try:
            prompt_text = build_prompt(st.session_state.history)

            parts = []
            if uploaded_files:
                for f in uploaded_files:
                    try:
                        img_bytes = f.getvalue()
                    except Exception:
                        f.seek(0)
                        img_bytes = f.read()

                    suffix = os.path.splitext(f.name)[1].lower()
                    if suffix in (".jpg", ".jpeg"):
                        mime = "image/jpeg"
                    elif suffix == ".png":
                        mime = "image/png"
                    elif suffix == ".webp":
                        mime = "image/webp"
                    else:
                        mime = "application/octet-stream"

                    parts.append(types.Part.from_bytes(data=img_bytes, mime_type=mime))

            # æ–‡å­—ä¸€å®šè¦ç”¨ keyword åƒæ•¸
            parts.append(types.Part.from_text(text=prompt_text))

            resp = client.models.generate_content(
                model=MODEL,
                contents=types.Content(role="user", parts=parts),
                config=types.GenerateContentConfig(
                    temperature=0.5,
                    top_p=0.9,
                    max_output_tokens=512,
                ),
            )

            reply = (getattr(resp, "text", "") or "").strip()
            if not reply and getattr(resp, "candidates", None):
                for c in resp.candidates:
                    if getattr(c, "content", None):
                        for p in getattr(c.content, "parts", []) or []:
                            if getattr(p, "text", None):
                                reply = p.text.strip()
                                if reply:
                                    break
                    if reply:
                        break
            if not reply and getattr(resp, "prompt_feedback", None):
                reply = f"(æ²’æœ‰æ–‡å­—å›æ‡‰ï¼Œå¯èƒ½è¢«éæ¿¾æˆ–ç„¡æ³•ç”¢ç”Ÿã€‚feedback={resp.prompt_feedback})"

            reply = reply or "(æ²’æœ‰å›æ‡‰å…§å®¹)"

        except Exception as e:
            st.error("å‘¼å« generate_content ç™¼ç”ŸéŒ¯èª¤")
            st.exception(e)
            reply = f"(ç™¼ç”ŸéŒ¯èª¤ï¼š{e})"

        st.markdown(reply)
        st.session_state.history.append({"role": "assistant", "text": reply})
