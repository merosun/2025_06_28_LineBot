import os
import streamlit as st
from google import genai
from google.genai import types
import inspect; print(inspect.signature(types.Part.from_text))  # å°å‡º from_text å‡½æ•¸çš„ç°½åï¼Œæ–¹ä¾¿ç¢ºèªåƒæ•¸

# ------------------ Streamlit é é¢è¨­å®š ------------------
st.set_page_config(page_title="Gemini Chat", page_icon="ğŸ’¬")  # è¨­å®šé é¢æ¨™é¡Œèˆ‡åœ–ç¤º

API_KEY = os.environ.get("GEMINI_API_KEY")  # å¾ç’°å¢ƒè®Šæ•¸å–å¾— Google Gemini API Key
MODEL = "gemini-2.5-flash"  # æŒ‡å®šä½¿ç”¨çš„ Gemini æ¨¡å‹

# å¦‚æœæ²’è¨­å®š API Keyï¼Œç›´æ¥é¡¯ç¤ºéŒ¯èª¤è¨Šæ¯ä¸¦åœæ­¢åŸ·è¡Œ
if not API_KEY:
    st.error("è«‹å…ˆè¨­å®š GEMINI_API_KEY ç’°å¢ƒè®Šæ•¸")
    st.stop()

# å»ºç«‹ Gemini API å®¢æˆ¶ç«¯
client = genai.Client(api_key=API_KEY)

# åˆå§‹åŒ–å°è©±æ­·å²ç´€éŒ„
if "history" not in st.session_state:
    st.session_state.history = []

# ------------------ é é¢æ¨™é¡Œ ------------------
st.title("ğŸ’¬ Gemini Chatï¼ˆç¹é«”ä¸­æ–‡ï¼‰")

# é¡¯ç¤ºæ­·å²å°è©±ï¼ˆå…ˆç”¨è§’è‰²åˆ¤æ–·æ˜¯ä½¿ç”¨è€…é‚„æ˜¯åŠ©ç†ï¼‰
for m in st.session_state.history:
    with st.chat_message("user" if m["role"] == "user" else "assistant"):
        st.markdown(m["text"])

# ------------------ æª”æ¡ˆä¸Šå‚³åŠŸèƒ½ ------------------
uploaded_files = st.file_uploader(
    "ï¼ˆé¸å¡«ï¼‰ä¸Šå‚³åœ–ç‰‡ï¼šæ”¯æ´ jpg/png/webp",
    type=["jpg", "jpeg", "png", "webp"],  # é™å®šæ”¯æ´çš„æª”æ¡ˆé¡å‹
    accept_multiple_files=True  # æ”¯æ´å¤šæª”ä¸Šå‚³
)

# å¦‚æœæœ‰ä¸Šå‚³æª”æ¡ˆï¼Œé è¦½åœ–ç‰‡
if uploaded_files:
    cols = st.columns(min(3, len(uploaded_files)))  # æ¯åˆ—æœ€å¤šé¡¯ç¤ºä¸‰å¼µåœ–
    for i, f in enumerate(uploaded_files):
        with cols[i % len(cols)]:
            st.image(f, caption=f.name, use_container_width=True)

# ------------------ ä½¿ç”¨è€…è¼¸å…¥å€ ------------------
user_input = st.chat_input("è¼¸å…¥ä½ çš„å•é¡Œâ€¦ï¼ˆå¯å…ˆé¸åœ–ç‰‡å†æå•ï¼‰")

# åªè¦ä½¿ç”¨è€…è¼¸å…¥æ–‡å­—æˆ–ä¸Šå‚³æª”æ¡ˆï¼Œå°±è™•ç†è«‹æ±‚
if user_input or uploaded_files:
    # é¡¯ç¤ºä½¿ç”¨è€…è¼¸å…¥
    display_text = user_input if user_input else "(ç„¡æ–‡å­—)"
    if uploaded_files:
        display_text += f"\nï¼ˆé™„ {len(uploaded_files)} å¼µåœ–ç‰‡ï¼‰"
    st.session_state.history.append({"role": "user", "text": display_text})

    with st.chat_message("user"):
        st.markdown(display_text)

    # ------------------ å»ºç«‹ Prompt å‡½æ•¸ ------------------
    def build_prompt(history):
        lines = ["ä½ æ˜¯ä¸€å€‹è‚¡å¸‚è²¡ç¶“å°ˆå®¶ï¼Œè«‹ç”¨ç¹é«”ä¸­æ–‡å›ç­”ã€‚ä»¥ä¸‹æ˜¯éå»å°è©±ï¼š"]
        for m in history:
            prefix = "ä½¿ç”¨è€…" if m["role"] == "user" else "åŠ©ç†"
            lines.append(f"{prefix}ï¼š{m['text']}")
        return "\n".join(lines)

    # ------------------ å‘¼å« Gemini API ------------------
    with st.chat_message("assistant"):
        try:
            prompt_text = build_prompt(st.session_state.history)

            parts = []
            # å¦‚æœæœ‰ä¸Šå‚³åœ–ç‰‡ï¼ŒæŠŠåœ–ç‰‡è½‰æˆ bytes ä¸¦åŠ åˆ° parts ä¸­
            if uploaded_files:
                for f in uploaded_files:
                    try:
                        img_bytes = f.getvalue()
                    except Exception:
                        f.seek(0)
                        img_bytes = f.read()

                    suffix = os.path.splitext(f.name)[1].lower()
                    if suffix in (".jpg", ".jpeg"):
                        mime = "image/jpeg"
                    elif suffix == ".png":
                        mime = "image/png"
                    elif suffix == ".webp":
                        mime = "image/webp"
                    else:
                        mime = "application/octet-stream"

                    parts.append(types.Part.from_bytes(data=img_bytes, mime_type=mime))

            # æ–‡å­—éƒ¨åˆ†ï¼ˆä¸€å®šè¦ç”¨ keyword åƒæ•¸ text=ï¼‰
            parts.append(types.Part.from_text(text=prompt_text))

            # å‘¼å« generate_content API
            resp = client.models.generate_content(
                model=MODEL,
                contents=types.Content(role="user", parts=parts),
                config=types.GenerateContentConfig(
                    temperature=0.5,  # å‰µæ„åº¦
                    top_p=0.9,        # å–æ¨£å¤šæ¨£æ€§
                    max_output_tokens=512,  # æœ€å¤§å›æ‡‰ token æ•¸
                ),
            )

            # å˜—è©¦å¾ resp å–å¾—æ–‡å­—å…§å®¹
            reply = (getattr(resp, "text", "") or "").strip()
            if not reply and getattr(resp, "candidates", None):
                for c in resp.candidates:
                    if getattr(c, "content", None):
                        for p in getattr(c.content, "parts", []) or []:
                            if getattr(p, "text", None):
                                reply = p.text.strip()
                                if reply:
                                    break
                    if reply:
                        break
            # å¦‚æœ API æœ‰å›å‚³ feedbackï¼Œä½†æ²’æœ‰æ–‡å­—å…§å®¹
            if not reply and getattr(resp, "prompt_feedback", None):
                reply = f"(æ²’æœ‰æ–‡å­—å›æ‡‰ï¼Œå¯èƒ½è¢«éæ¿¾æˆ–ç„¡æ³•ç”¢ç”Ÿã€‚feedback={resp.prompt_feedback})"

            reply = reply or "(æ²’æœ‰å›æ‡‰å…§å®¹)"

        except Exception as e:
            # æ•æ‰éŒ¯èª¤ä¸¦é¡¯ç¤º
            st.error("å‘¼å« generate_content ç™¼ç”ŸéŒ¯èª¤")
            st.exception(e)
            reply = f"(ç™¼ç”ŸéŒ¯èª¤ï¼š{e})"

        # é¡¯ç¤ºåŠ©ç†çš„å›æ‡‰
        st.markdown(reply)
        st.session_state.history.append({"role": "assistant", "text": reply})
